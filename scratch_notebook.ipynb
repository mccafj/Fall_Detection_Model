{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratch notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3f95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can any of these be deleted for the final notebook?\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression,\\\n",
    "LassoCV, RidgeCV, ElasticNetCV, LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, \\\n",
    "cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, \\\n",
    "FunctionTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, \\\n",
    "precision_score, recall_score, accuracy_score, f1_score, \\\n",
    "log_loss, roc_curve, roc_auc_score, classification_report \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e0a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# didn't get in yet:  from sklearn.metrics import plot_confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0403262b",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347bb661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2561c3",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463bfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b94def42",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c4fd3",
   "metadata": {},
   "source": [
    "I am interested in taking raw data from a body-worn sensor on simulated activities, including falls, to create a model that will accurately predict when a person has had a fall or not.  As a former physical therapist who worked in a variety of settings, I believe there is great value in having real-time recognition of a fall event for a patient so staff/family can receive immediate notice and the patient can receive prompt medical attention.  This business challenge applies to the healthcare industry, and could be relevant across the continuum of care, from an acute care hospital environment, to a subacute/rehab setting, a long-term care/nursing home, or even to elderly residents residing alone in the community with family support.  My target audience would ideally include administrators considering better real-time fall monitoring in their facilities, or even to family members of elderly residents living independently.  In addition to the original research that provided this dataset, my analysis would be further proof that this monitoring system can yield accurate and actionable information that would improve patient safety and reduce costly medical complications related to falls.  My domain knowledge includes 15 years of experience as a physical therapist in acute care, rehabs / long term care, outpatient, and home care environments.  I also recently did a __[blog post](https://medium.com/@jonmccaffrey524/deep-learning-and-human-activity-recognition-98cb43da229)__ on deep learning and human activity recognition, and read the __[paper](https://arcoresearch.com/2021/11/23/the-shapes-smart-mirror-approach-for-independent-living-healthy-and-active-ageing/)__ published by the ARCO research group related to their fall monitoring system.  In summary, I am motivated by the fact that falls in healthcare facilities and in the home can be a cause of serious injury and complications for patients / residents, as well as be tremendously costly to our healthcare system.  Though this project doesn’t aim to prevent falls, it does aim to verify accurate diagnosis that a fall has occurred based on sensor-data provided, to help contribute to the goal of improved real-time monitoring and hopefully emergent medical management for someone who has sustained a fall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cae0dc2",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3290e1",
   "metadata": {},
   "source": [
    "The data I plan to explore and model on comes from theARCO research group in Spain.  It involves activity-monitoring recording of 17 participants undergoing a variety of Activity of Daily Living (ADL) tasks as well as simulated falls.  The data was obtained __[here](https://arcoresearch.com/2021/04/16/dataset-for-fall-detection/)__, and downloaded as a .zip file.  The features include detailed sensor information for acceleration (in g), rotation (in deg/sec), and absolute orientation in Euler angles.  There are 3 different folders of CSV files in total.  Included in the data is a clear target (0 or 1) indicating if a fall occurred during the recording of the activity.     Previous work has been done by the authors, who reference a “machine learning algorithm” they created with “100% accuracy” in a “controlled environment”.  Though the details of the algorithm are vague, I aim to try to replicate their findings while also building my own machine-learning understanding for human activity recognition tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5694822",
   "metadata": {},
   "source": [
    "Subject\tAge\tWeight(Kg)\tHeight(m)\n",
    "1\t24\t84\t1.90\n",
    "2\t27\t90\t1.70\n",
    "3\t24\t69\t1.80\n",
    "4\t24\t65\t1.59\n",
    "5\t43\t83\t1.77\n",
    "6\t27\t65\t1.70\n",
    "7\t34\t76\t1.76\n",
    "8\t42\t89\t1.84\n",
    "9\t24\t65\t1.75\n",
    "10\t24\t56.2\t1.75\n",
    "11\t23\t74.3\t1.72\n",
    "12\t22\t85\t1.72\n",
    "13\t41\t72\t1.65\n",
    "14\t36\t80\t1.85\n",
    "15\t31\t75\t1.64\n",
    "16\t22\t64.5\t1.71\n",
    "17\t43\t71\t1.76"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc78d1",
   "metadata": {},
   "source": [
    "fall-dataset-features: Each row of this dataset  contains the features used in our study to filter raw data and describe a movement. Each row represents a complete exericse (Fall or ADL)\n",
    "\n",
    "fall-dataset-raw: Raw data from a one second window when the user perfomed the activity. Each row alone is not relevant because it only contains raw data in a instant of time. In order to get relevant information you must use all the data with the same value on the column index, all this data are part of the same exercise along the time.\n",
    "\n",
    "fall-dataset-all: On these files, all the data collected when the exercises were performed by the users is saved. It could be useful if you need data out of the one second window. This data is not labeled, but you can use fall-dataset-raw in order to find when a fall or an ADLs were produced. Both fall-dataset-raw and fall-dataset-all have timestamp in order to ease this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab7161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4764dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31adc963",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf1fb6",
   "metadata": {},
   "source": [
    "The .zip file contains 3 folders of CSV files of data.  \n",
    "- The 1st folder contains 17 CSV files (one for each participant) with all the raw data (11 columns each, 2800 rows each) but summarized/indexed by the task being performed.  \n",
    "- The 2nd folder contains 17 CSV files with all the features information (25 columns each, 45 rows each - representing summations of each of 45 tasks, including simulated falls)\n",
    "- The 3rd folder contains 17 CSV files of all the raw data for each participant (10 columns, 30K rows) NOT summarized / indexed by task.\n",
    "\n",
    "The data types are all numeric (int or float), though that includes a timestamp variable and the 0/1 boolean of fall occurrence.  The division between data that represent falls vs. non-fall tasks appears about evenly divided, so there is not a significant class imbalance.  Also, the amount of data available for each task being performed (45 total), for each participant (17 total), appears roughly equal.  The libraries I intend to use include at least Pandas, NumPy, sklearn, matplotlib, and Seaborn.  As far as preprocessing, the data is very clean with no nulls.  Pre-processing may include clustering to see if any groupings can be discerned from that.  It may require scaling and dimensionality reduction as well.  I will need more domain knowledge related to the units of acceleration, rotation, and absolute orientation in Euler angles.  At a minimum, it appears I would utilize the 1st folder (raw data summarized/indexed by task) which contains ~2800 rows per participant.  Visualizations could include confusion matrices and ROC curves for iterative modeling, then separate visuals to represent accuracy by tasks (stacked bar graph?).  I could also do a bar graph for eventual feature importance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179dd692",
   "metadata": {},
   "source": [
    "## Unzipping folders in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691087ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# files too large (~117MB) to save on GitHub unless they remain compressed (~30MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cb6fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JonMc\\Documents\\Flatiron\\Fall_Detection_Model\\data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f00f45db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 62FE-3091\n",
      "\n",
      " Directory of C:\\Users\\JonMc\\Documents\\Flatiron\\Fall_Detection_Model\\data\n",
      "\n",
      "12/12/2022  05:15 PM    <DIR>          .\n",
      "12/12/2022  05:13 PM    <DIR>          ..\n",
      "12/12/2022  09:31 AM        31,452,115 fall-dataset.zip\n",
      "12/12/2022  09:31 AM           227,728 test_dataset.zip\n",
      "               2 File(s)     31,679,843 bytes\n",
      "               2 Dir(s)  385,159,757,824 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43705810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  fall-dataset.zip\n",
      "   creating: fall-dataset/\n",
      "   creating: fall-dataset/fall-dataset-features/\n",
      "  inflating: fall-dataset/fall-dataset-features/Subject10.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject11.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject12.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject13.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject14.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject15.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject16.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject17.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject1.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject2.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject3.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject4.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject5.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject6.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject7.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject8.csv  \n",
      "  inflating: fall-dataset/fall-dataset-features/Subject9.csv  \n",
      "   creating: fall-dataset/fall-dataset-all/\n",
      "  inflating: fall-dataset/fall-dataset-all/Subject10-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject11-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject12-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject13-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject14-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject15-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject16-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject17-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject1-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject2-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject3-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject4-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject5-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject6-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject7-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject8-raw-all.csv  \n",
      "  inflating: fall-dataset/fall-dataset-all/Subject9-raw-all.csv  \n",
      "   creating: fall-dataset/fall-dataset-raw/\n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject1-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject2-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject3-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject4-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject5-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject6-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject7-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject8-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject9-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject10-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject11-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject12-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject13-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject14-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject15-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject16-raw.csv  \n",
      "  inflating: fall-dataset/fall-dataset-raw/Subject17-raw.csv  \n"
     ]
    }
   ],
   "source": [
    "! unzip fall-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c726209",
   "metadata": {},
   "source": [
    "## Creating a dataframe for fall-dataset-raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2d9f331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can replace this pathname with the full path to the folder locally\n",
    "path_raw = r'C:\\Users\\JonMc\\Documents\\Flatiron\\Fall_Detection_Model\\data\\fall-dataset\\fall-dataset-raw' \n",
    "\n",
    "# Get the files from the path provided\n",
    "files_raw = Path(path_raw).glob('*.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1fbff135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this for loop will create a separate column based on the filename, to separate subjects if needed\n",
    "\n",
    "dfs_1 = []\n",
    "for f in files_raw:\n",
    "    data = pd.read_csv(f)\n",
    "    # .stem is method for pathlib objects to get the filename w/o the extension\n",
    "    data['File'] = f.stem\n",
    "    dfs_1.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "72044547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all 17 files into one dataframe\n",
    "df_raw = pd.concat(dfs_1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3a4b1f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Line</th>\n",
       "      <th>Acc(X)</th>\n",
       "      <th>Acc(Y)</th>\n",
       "      <th>Acc(Z)</th>\n",
       "      <th>Rot(X)</th>\n",
       "      <th>Rot(Y)</th>\n",
       "      <th>Rot(Z)</th>\n",
       "      <th>Pitch</th>\n",
       "      <th>Roll</th>\n",
       "      <th>Yaw</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Fall</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.191406</td>\n",
       "      <td>0.768555</td>\n",
       "      <td>8.799805</td>\n",
       "      <td>98.841469</td>\n",
       "      <td>-488.109772</td>\n",
       "      <td>-94.939026</td>\n",
       "      <td>8.554567</td>\n",
       "      <td>68.015976</td>\n",
       "      <td>354.055115</td>\n",
       "      <td>1612546353614</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.965820</td>\n",
       "      <td>0.224121</td>\n",
       "      <td>2.638672</td>\n",
       "      <td>-261.890259</td>\n",
       "      <td>-15.853659</td>\n",
       "      <td>-24.634148</td>\n",
       "      <td>7.382404</td>\n",
       "      <td>72.709183</td>\n",
       "      <td>353.782318</td>\n",
       "      <td>1612546353616</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.854980</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.548828</td>\n",
       "      <td>-337.865875</td>\n",
       "      <td>535.853699</td>\n",
       "      <td>49.817074</td>\n",
       "      <td>7.836745</td>\n",
       "      <td>72.958641</td>\n",
       "      <td>355.967834</td>\n",
       "      <td>1612546353657</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.238770</td>\n",
       "      <td>-2.900391</td>\n",
       "      <td>-6.257324</td>\n",
       "      <td>-254.207321</td>\n",
       "      <td>460.792694</td>\n",
       "      <td>49.817074</td>\n",
       "      <td>10.936003</td>\n",
       "      <td>65.359154</td>\n",
       "      <td>0.667080</td>\n",
       "      <td>1612546353659</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.804688</td>\n",
       "      <td>2.567871</td>\n",
       "      <td>-0.529297</td>\n",
       "      <td>741.890259</td>\n",
       "      <td>-307.500000</td>\n",
       "      <td>107.073174</td>\n",
       "      <td>26.398607</td>\n",
       "      <td>61.147324</td>\n",
       "      <td>2.398508</td>\n",
       "      <td>1612546353661</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Line    Acc(X)    Acc(Y)    Acc(Z)      Rot(X)      Rot(Y)  \\\n",
       "0             1  3.191406  0.768555  8.799805   98.841469 -488.109772   \n",
       "1             1  2.965820  0.224121  2.638672 -261.890259  -15.853659   \n",
       "2             1  0.854980  0.500000  0.548828 -337.865875  535.853699   \n",
       "3             1 -1.238770 -2.900391 -6.257324 -254.207321  460.792694   \n",
       "4             1  1.804688  2.567871 -0.529297  741.890259 -307.500000   \n",
       "\n",
       "       Rot(Z)      Pitch       Roll         Yaw      Timestamp  Fall  \\\n",
       "0  -94.939026   8.554567  68.015976  354.055115  1612546353614     0   \n",
       "1  -24.634148   7.382404  72.709183  353.782318  1612546353616     0   \n",
       "2   49.817074   7.836745  72.958641  355.967834  1612546353657     0   \n",
       "3   49.817074  10.936003  65.359154    0.667080  1612546353659     0   \n",
       "4  107.073174  26.398607  61.147324    2.398508  1612546353661     0   \n",
       "\n",
       "           File  \n",
       "0  Subject1-raw  \n",
       "1  Subject1-raw  \n",
       "2  Subject1-raw  \n",
       "3  Subject1-raw  \n",
       "4  Subject1-raw  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4fcc9eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject15-raw    3370\n",
       "Subject9-raw     3166\n",
       "Subject2-raw     3150\n",
       "Subject3-raw     3109\n",
       "Subject8-raw     3019\n",
       "Subject13-raw    2935\n",
       "Subject10-raw    2924\n",
       "Subject5-raw     2899\n",
       "Subject14-raw    2897\n",
       "Subject7-raw     2896\n",
       "Subject11-raw    2872\n",
       "Subject17-raw    2847\n",
       "Subject6-raw     2837\n",
       "Subject4-raw     2770\n",
       "Subject1-raw     2755\n",
       "Subject16-raw    2722\n",
       "Subject12-raw    2545\n",
       "Name: File, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value counts per subject\n",
    "df_raw['File'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afec6333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature Line    0\n",
       "Acc(X)          0\n",
       "Acc(Y)          0\n",
       "Acc(Z)          0\n",
       "Rot(X)          0\n",
       "Rot(Y)          0\n",
       "Rot(Z)          0\n",
       "Pitch           0\n",
       "Roll            0\n",
       "Yaw             0\n",
       "Timestamp       0\n",
       "Fall            0\n",
       "File            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no nulls\n",
    "df_raw.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c23510",
   "metadata": {},
   "source": [
    "## Creating a dataframe for fall-dataset-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "862d764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can replace this pathname with the full path to the folder locally\n",
    "path_all = r'C:\\Users\\JonMc\\Documents\\Flatiron\\Fall_Detection_Model\\data\\fall-dataset\\fall-dataset-all' \n",
    "\n",
    "# Get the files from the path provided\n",
    "files_all = Path(path_all).glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fa952f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this for loop will create a separate column based on the filename, to separate subjects if needed\n",
    "\n",
    "dfs_2 = []\n",
    "for f in files_all:\n",
    "    data = pd.read_csv(f)\n",
    "    # .stem is method for pathlib objects to get the filename w/o the extension\n",
    "    data['File'] = f.stem\n",
    "    dfs_2.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1120b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all 17 files into one dataframe\n",
    "df_all = pd.concat(dfs_2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67117640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc(X)</th>\n",
       "      <th>Acc(Y)</th>\n",
       "      <th>Acc(Z)</th>\n",
       "      <th>Rot(X)</th>\n",
       "      <th>Rot(Y)</th>\n",
       "      <th>Rot(Z)</th>\n",
       "      <th>Pitch</th>\n",
       "      <th>Roll</th>\n",
       "      <th>Yaw</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932617</td>\n",
       "      <td>-0.166504</td>\n",
       "      <td>0.411133</td>\n",
       "      <td>3.231707</td>\n",
       "      <td>-2.865854</td>\n",
       "      <td>3.536585</td>\n",
       "      <td>9.411585</td>\n",
       "      <td>64.421898</td>\n",
       "      <td>359.941193</td>\n",
       "      <td>1612546351138</td>\n",
       "      <td>Subject1-raw-all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.934570</td>\n",
       "      <td>-0.166016</td>\n",
       "      <td>0.398926</td>\n",
       "      <td>3.109756</td>\n",
       "      <td>-1.280488</td>\n",
       "      <td>3.353659</td>\n",
       "      <td>9.430594</td>\n",
       "      <td>64.434891</td>\n",
       "      <td>359.882324</td>\n",
       "      <td>1612546351140</td>\n",
       "      <td>Subject1-raw-all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938477</td>\n",
       "      <td>-0.170410</td>\n",
       "      <td>0.387207</td>\n",
       "      <td>2.317073</td>\n",
       "      <td>-0.609756</td>\n",
       "      <td>2.987805</td>\n",
       "      <td>9.448231</td>\n",
       "      <td>64.434715</td>\n",
       "      <td>359.828003</td>\n",
       "      <td>1612546351141</td>\n",
       "      <td>Subject1-raw-all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.937988</td>\n",
       "      <td>-0.176270</td>\n",
       "      <td>0.380371</td>\n",
       "      <td>2.195122</td>\n",
       "      <td>-0.731707</td>\n",
       "      <td>2.621951</td>\n",
       "      <td>9.465791</td>\n",
       "      <td>64.432030</td>\n",
       "      <td>359.783264</td>\n",
       "      <td>1612546351182</td>\n",
       "      <td>Subject1-raw-all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.937012</td>\n",
       "      <td>-0.173340</td>\n",
       "      <td>0.384766</td>\n",
       "      <td>2.195122</td>\n",
       "      <td>-1.463415</td>\n",
       "      <td>2.256098</td>\n",
       "      <td>9.481668</td>\n",
       "      <td>64.436104</td>\n",
       "      <td>359.742218</td>\n",
       "      <td>1612546351184</td>\n",
       "      <td>Subject1-raw-all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Acc(X)    Acc(Y)    Acc(Z)    Rot(X)    Rot(Y)    Rot(Z)     Pitch  \\\n",
       "0  0.932617 -0.166504  0.411133  3.231707 -2.865854  3.536585  9.411585   \n",
       "1  0.934570 -0.166016  0.398926  3.109756 -1.280488  3.353659  9.430594   \n",
       "2  0.938477 -0.170410  0.387207  2.317073 -0.609756  2.987805  9.448231   \n",
       "3  0.937988 -0.176270  0.380371  2.195122 -0.731707  2.621951  9.465791   \n",
       "4  0.937012 -0.173340  0.384766  2.195122 -1.463415  2.256098  9.481668   \n",
       "\n",
       "        Roll         Yaw      Timestamp              File  \n",
       "0  64.421898  359.941193  1612546351138  Subject1-raw-all  \n",
       "1  64.434891  359.882324  1612546351140  Subject1-raw-all  \n",
       "2  64.434715  359.828003  1612546351141  Subject1-raw-all  \n",
       "3  64.432030  359.783264  1612546351182  Subject1-raw-all  \n",
       "4  64.436104  359.742218  1612546351184  Subject1-raw-all  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b3cd70ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject15-raw-all    75650\n",
       "Subject2-raw-all     57617\n",
       "Subject8-raw-all     53069\n",
       "Subject14-raw-all    47176\n",
       "Subject9-raw-all     43937\n",
       "Subject7-raw-all     43639\n",
       "Subject10-raw-all    39043\n",
       "Subject17-raw-all    38285\n",
       "Subject12-raw-all    37134\n",
       "Subject3-raw-all     34303\n",
       "Subject4-raw-all     34194\n",
       "Subject5-raw-all     32879\n",
       "Subject13-raw-all    32634\n",
       "Subject11-raw-all    29949\n",
       "Subject1-raw-all     29551\n",
       "Subject6-raw-all     25949\n",
       "Subject16-raw-all    23706\n",
       "Name: File, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['File'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66767a90",
   "metadata": {},
   "source": [
    "## Creating a dataframe for fall-dataset-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "322f5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can replace this pathname with the full path to the folder locally\n",
    "path_feat = r'C:\\Users\\JonMc\\Documents\\Flatiron\\Fall_Detection_Model\\data\\fall-dataset\\fall-dataset-raw' \n",
    "\n",
    "# Get the files from the path provided\n",
    "files_feat = Path(path_feat).glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5eceea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this for loop will create a separate column based on the filename, to separate subjects if needed\n",
    "\n",
    "dfs_3 = []\n",
    "for f in files_feat:\n",
    "    data = pd.read_csv(f)\n",
    "    # .stem is method for pathlib objects to get the filename w/o the extension\n",
    "    data['File'] = f.stem\n",
    "    dfs_3.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b01f4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all 17 files into one dataframe\n",
    "df_feat = pd.concat(dfs_3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ce96f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Line</th>\n",
       "      <th>Acc(X)</th>\n",
       "      <th>Acc(Y)</th>\n",
       "      <th>Acc(Z)</th>\n",
       "      <th>Rot(X)</th>\n",
       "      <th>Rot(Y)</th>\n",
       "      <th>Rot(Z)</th>\n",
       "      <th>Pitch</th>\n",
       "      <th>Roll</th>\n",
       "      <th>Yaw</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Fall</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.191406</td>\n",
       "      <td>0.768555</td>\n",
       "      <td>8.799805</td>\n",
       "      <td>98.841469</td>\n",
       "      <td>-488.109772</td>\n",
       "      <td>-94.939026</td>\n",
       "      <td>8.554567</td>\n",
       "      <td>68.015976</td>\n",
       "      <td>354.055115</td>\n",
       "      <td>1612546353614</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.965820</td>\n",
       "      <td>0.224121</td>\n",
       "      <td>2.638672</td>\n",
       "      <td>-261.890259</td>\n",
       "      <td>-15.853659</td>\n",
       "      <td>-24.634148</td>\n",
       "      <td>7.382404</td>\n",
       "      <td>72.709183</td>\n",
       "      <td>353.782318</td>\n",
       "      <td>1612546353616</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.854980</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.548828</td>\n",
       "      <td>-337.865875</td>\n",
       "      <td>535.853699</td>\n",
       "      <td>49.817074</td>\n",
       "      <td>7.836745</td>\n",
       "      <td>72.958641</td>\n",
       "      <td>355.967834</td>\n",
       "      <td>1612546353657</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.238770</td>\n",
       "      <td>-2.900391</td>\n",
       "      <td>-6.257324</td>\n",
       "      <td>-254.207321</td>\n",
       "      <td>460.792694</td>\n",
       "      <td>49.817074</td>\n",
       "      <td>10.936003</td>\n",
       "      <td>65.359154</td>\n",
       "      <td>0.667080</td>\n",
       "      <td>1612546353659</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.804688</td>\n",
       "      <td>2.567871</td>\n",
       "      <td>-0.529297</td>\n",
       "      <td>741.890259</td>\n",
       "      <td>-307.500000</td>\n",
       "      <td>107.073174</td>\n",
       "      <td>26.398607</td>\n",
       "      <td>61.147324</td>\n",
       "      <td>2.398508</td>\n",
       "      <td>1612546353661</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject1-raw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Line    Acc(X)    Acc(Y)    Acc(Z)      Rot(X)      Rot(Y)  \\\n",
       "0             1  3.191406  0.768555  8.799805   98.841469 -488.109772   \n",
       "1             1  2.965820  0.224121  2.638672 -261.890259  -15.853659   \n",
       "2             1  0.854980  0.500000  0.548828 -337.865875  535.853699   \n",
       "3             1 -1.238770 -2.900391 -6.257324 -254.207321  460.792694   \n",
       "4             1  1.804688  2.567871 -0.529297  741.890259 -307.500000   \n",
       "\n",
       "       Rot(Z)      Pitch       Roll         Yaw      Timestamp  Fall  \\\n",
       "0  -94.939026   8.554567  68.015976  354.055115  1612546353614     0   \n",
       "1  -24.634148   7.382404  72.709183  353.782318  1612546353616     0   \n",
       "2   49.817074   7.836745  72.958641  355.967834  1612546353657     0   \n",
       "3   49.817074  10.936003  65.359154    0.667080  1612546353659     0   \n",
       "4  107.073174  26.398607  61.147324    2.398508  1612546353661     0   \n",
       "\n",
       "           File  \n",
       "0  Subject1-raw  \n",
       "1  Subject1-raw  \n",
       "2  Subject1-raw  \n",
       "3  Subject1-raw  \n",
       "4  Subject1-raw  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "30738bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject15-raw    3370\n",
       "Subject9-raw     3166\n",
       "Subject2-raw     3150\n",
       "Subject3-raw     3109\n",
       "Subject8-raw     3019\n",
       "Subject13-raw    2935\n",
       "Subject10-raw    2924\n",
       "Subject5-raw     2899\n",
       "Subject14-raw    2897\n",
       "Subject7-raw     2896\n",
       "Subject11-raw    2872\n",
       "Subject17-raw    2847\n",
       "Subject6-raw     2837\n",
       "Subject4-raw     2770\n",
       "Subject1-raw     2755\n",
       "Subject16-raw    2722\n",
       "Subject12-raw    2545\n",
       "Name: File, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat['File'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade1d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26ca21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6c147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be3647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1471c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329ea8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8a1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e53cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e27e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367cd481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ec25151",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7703cb",
   "metadata": {},
   "source": [
    "Modeling will involve the use of a train-test split, a baseline dummy classifier, then pipelines and cross-validation for logistic regression, kNN, decision trees / random forest, grid searches, XG boosting.  My target variable is the defined 0 or 1 for whether a fall occurred in that segment of testing, which indicates a binary classification problem.  My local computer should be sufficient for this, as it was in phase 3, but I am open to using Google Colab  if I need additional computing power, or if the processing speed on my own computer is woefully slow.  My data will be stored on my local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c4500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35849b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e17332ec",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba36f175",
   "metadata": {},
   "source": [
    "My chosen metrics for evaluation are accuracy and recall (aiming to reduce false negatives, therefore catching almost all or all of the falls that occurred in the data).  The MVP involves finding the best model with the highest accuracy and recall possible in a reasonable timeframe with the computational resources I have available.  The smaller project I hope to accomplish this first week is to get through Random Forest models and into Grid Searching to optimize those models.  XG boosting will likely have to wait until next week.  For a level up, I am considering deploying the best model with examples and explanations via Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd98ba",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5521840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c805f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29953906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit_09",
   "language": "python",
   "name": "streamlit_09"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
